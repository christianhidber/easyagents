{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eU7ylMh1kQ2y"
   },
   "source": [
    "# Berater Environment v13 (Orso's live)\n",
    "\n",
    "## Changes from v12 (work in progress)\n",
    "* migration to easyagents\n",
    "* Max. number of steps management and debug logging migrated to easyagents.TrainingDuration\n",
    "* render yields the last step, supporting modes 'ansi', 'human', 'rgb_array'\n",
    "* the story of Orso\n",
    "* image rendering in graph layout\n",
    "* plot statistics and state during training\n",
    "* DqnAgent\n",
    "* Orso rendering fine tuned \n",
    "* support for gym registration with different implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sQ8Nfk3MKgLt"
   },
   "source": [
    "### Install gym, tensorflow, tf-agents,..., setup display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QFQXRNBFI5Re",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q easyagents\n",
    "!pip install -q networkx==2.3.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### suppress package warnings, in colab: load additional packages for rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DcilvDdeI5Ri",
    "outputId": "764ebfe5-ad79-4cad-c9fa-34ae33b6e3e2",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "if 'google.colab' in sys.modules:\n",
    "    !apt-get install xvfb >/dev/null\n",
    "    !pip install pyvirtualdisplay >/dev/null    \n",
    "    \n",
    "    from pyvirtualdisplay import Display\n",
    "    Display(visible=0, size=(960, 720)).start() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w3OdHyWEEEwy"
   },
   "source": [
    "# Define Gym Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9k_obuGGI5Rk"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HQyb_Aq8Kg9j",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym.utils import seeding\n",
    "from gym import spaces\n",
    "import matplotlib.image as mpi\n",
    "from matplotlib.offsetbox import (OffsetImage, AnnotationBbox)\n",
    "from IPython.display import display, clear_output\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OsJ6zcXvwN53"
   },
   "source": [
    "### Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-S4sZG5ZkQ3T",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def state_name_to_int(state):\n",
    "    state_name_map = {\n",
    "        'S': 0,\n",
    "        'A': 1,\n",
    "        'B': 2,\n",
    "        'C': 3,\n",
    "        'D': 4,\n",
    "        'E': 5,\n",
    "        'F': 6,\n",
    "        'G': 7,\n",
    "        'H': 8,\n",
    "        'K': 9,\n",
    "        'L': 10,\n",
    "        'M': 11,\n",
    "        'N': 12,\n",
    "        'O': 13\n",
    "    }\n",
    "    return state_name_map[state]\n",
    "\n",
    "def int_to_state_name(state_as_int):\n",
    "    state_map = {\n",
    "        0: 'S',\n",
    "        1: 'A',\n",
    "        2: 'B',\n",
    "        3: 'C',\n",
    "        4: 'D',\n",
    "        5: 'E',\n",
    "        6: 'F',\n",
    "        7: 'G',\n",
    "        8: 'H',\n",
    "        9: 'K',\n",
    "        10: 'L',\n",
    "        11: 'M',\n",
    "        12: 'N',\n",
    "        13: 'O'\n",
    "    }\n",
    "    return state_map[state_as_int]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x-olom0nwiSX"
   },
   "source": [
    "### Berater Environment (OpenAI Gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3plH2u3Swotj",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class BeraterEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    The Berater Problem\n",
    "\n",
    "    Actions:\n",
    "    There are 4 discrete deterministic actions, each choosing one direction\n",
    "    \"\"\"\n",
    "    metadata = {'render.modes': ['ansi']}\n",
    "    showStep = False\n",
    "\n",
    "    def __init__(self):\n",
    "        #         self.map = {\n",
    "        #             'S': [('A', 100), ('B', 400), ('C', 200 )],\n",
    "        #             'A': [('B', 250), ('C', 400), ('S', 100 )],\n",
    "        #             'B': [('A', 250), ('C', 250), ('S', 400 )],\n",
    "        #             'C': [('A', 400), ('B', 250), ('S', 200 )]\n",
    "        #         }\n",
    "        self.map = {\n",
    "            'S': [('A', 300), ('B', 100), ('C', 200)],\n",
    "            'A': [('S', 300), ('B', 100), ('E', 100), ('D', 100)],\n",
    "            'B': [('S', 100), ('A', 100), ('C', 50), ('K', 200)],\n",
    "            'C': [('S', 200), ('B', 50), ('M', 100), ('L', 200)],\n",
    "            'D': [('A', 100), ('F', 50)],\n",
    "            'E': [('A', 100), ('F', 100), ('H', 100)],\n",
    "            'F': [('D', 50), ('E', 100), ('G', 200)],\n",
    "            'G': [('F', 200), ('O', 300)],\n",
    "            'H': [('E', 100), ('K', 300)],\n",
    "            'K': [('B', 200), ('H', 300)],\n",
    "            'L': [('C', 200), ('M', 50)],\n",
    "            'M': [('C', 100), ('L', 50), ('N', 100)],\n",
    "            'N': [('M', 100), ('O', 100)],\n",
    "            'O': [('N', 100), ('G', 300)]\n",
    "        }\n",
    "        max_paths = 4\n",
    "        self.action_space = spaces.Discrete(max_paths)\n",
    "\n",
    "        positions = len(self.map)\n",
    "        # observations: position, reward of all 4 local paths, rest reward of all locations\n",
    "        # non existing path is -1000 and no position change\n",
    "        # look at what #getObservation returns if you are confused\n",
    "        low = np.append(np.append([0], np.full(max_paths, -1000)), np.full(positions, 0))\n",
    "        high = np.append(np.append([positions - 1], np.full(max_paths, 1000)), np.full(positions, 1000))\n",
    "        self.observation_space = spaces.Box(low=low,\n",
    "                                            high=high,\n",
    "                                            dtype=np.float32)\n",
    "        self.reward_range = (-1, 1)\n",
    "        self.envEpisodeCount = 0\n",
    "        self.envStepCount = 0\n",
    "        self._figure = None\n",
    "\n",
    "        self.reset()\n",
    "        self.optimum = self.calculate_customers_reward()\n",
    "\n",
    "        base = \"https://raw.githubusercontent.com/christianhidber/easyagents/master/images/\"\n",
    "        self.image_orso = mpi.imread(base + \"Bear.png\")\n",
    "        self.image_cave = mpi.imread(base + \"Cave.png\")\n",
    "        self.image_honey = mpi.imread(base + \"Honey.png\")\n",
    "        self.image_empty_pot = mpi.imread(base + \"EmptyPot.png\")\n",
    "        self.nx_graph, self.nx_pos = self._create_nx_graph()\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def iterate_path(self, state, action):\n",
    "        paths = self.map[state]\n",
    "        if action < len(paths):\n",
    "            return paths[action]\n",
    "        else:\n",
    "            # sorry, no such action, stay where you are and pay a high penalty\n",
    "            return (state, 1000)\n",
    "\n",
    "    def step(self, action):\n",
    "        destination, cost = self.iterate_path(self.state, action)\n",
    "\n",
    "        self.cost = cost\n",
    "        self.action = action\n",
    "        self.lastStep_state = self.state\n",
    "        self.state = destination\n",
    "        self.customerReward = self.customer_reward[destination]\n",
    "        self.reward = 0\n",
    "        self.reward = (self.customerReward - self.cost) / self.optimum\n",
    "\n",
    "        self.customer_visited(destination)\n",
    "        done = (destination == 'S' and self.all_customers_visited())\n",
    "\n",
    "        stateAsInt = state_name_to_int(self.state)\n",
    "        self.totalReward += self.reward\n",
    "        self.stepCount += 1\n",
    "        self.envStepCount += 1\n",
    "\n",
    "        if done and not self.isDone:\n",
    "            self.envEpisodeCount += 1\n",
    "\n",
    "        self.isDone = done\n",
    "        observation = self.getObservation(stateAsInt)\n",
    "        info = {\"from\": self.state, \"to\": destination}\n",
    "        return observation, self.reward, done, info\n",
    "\n",
    "    def getObservation(self, position):\n",
    "        result = np.array([position,\n",
    "                           self.getPathObservation(position, 0),\n",
    "                           self.getPathObservation(position, 1),\n",
    "                           self.getPathObservation(position, 2),\n",
    "                           self.getPathObservation(position, 3)\n",
    "                           ],\n",
    "                          dtype=np.float32)\n",
    "        all_rest_rewards = list(self.customer_reward.values())\n",
    "        result = np.append(result, all_rest_rewards)\n",
    "        return result\n",
    "\n",
    "    def getPathObservation(self, position, path):\n",
    "        paths = self.map[self.state]\n",
    "        if path < len(paths):\n",
    "            target, cost = paths[path]\n",
    "            reward = self.customer_reward[target]\n",
    "            result = reward - cost\n",
    "        else:\n",
    "            result = -1000\n",
    "\n",
    "        return result\n",
    "\n",
    "    def customer_visited(self, customer):\n",
    "        self.customer_reward[customer] = 0\n",
    "\n",
    "    def all_customers_visited(self):\n",
    "        return self.calculate_customers_reward() == 0\n",
    "\n",
    "    def calculate_customers_reward(self):\n",
    "        sum = 0\n",
    "        for value in self.customer_reward.values():\n",
    "            sum += value\n",
    "        return sum\n",
    "\n",
    "    def modulate_reward(self):\n",
    "        number_of_customers = len(self.map) - 1\n",
    "        number_per_consultant = int(number_of_customers / 2)\n",
    "        self.customer_reward = {\n",
    "            'S': 0\n",
    "        }\n",
    "        self._honeypot_places = []\n",
    "        for customer_nr in range(1, number_of_customers + 1):\n",
    "            self.customer_reward[int_to_state_name(customer_nr)] = 0\n",
    "\n",
    "        # every consultant only visits a few random customers\n",
    "        samples = random.sample(range(1, number_of_customers + 1), k=number_per_consultant)\n",
    "        key_list = list(self.customer_reward.keys())\n",
    "        for sample in samples:\n",
    "            self.customer_reward[key_list[sample]] = 1000\n",
    "            self._honeypot_places = self._honeypot_places + [key_list[sample]]\n",
    "\n",
    "    def reset(self):\n",
    "        self.totalReward = 0\n",
    "        self.stepCount = 0\n",
    "        self.isDone = False\n",
    "        self.state = 'S'\n",
    "        self.cost = 0\n",
    "        self.action = 0\n",
    "        self.lastStep_state = ''\n",
    "        self.customerReward = None\n",
    "        self._honeypot_places = None\n",
    "        self.reward = 0\n",
    "        self.envEpisodeCount += 1\n",
    "        self.modulate_reward()\n",
    "        self._figure = None\n",
    "        return self.getObservation(state_name_to_int(self.state))\n",
    "\n",
    "    def _create_nx_graph(self):\n",
    "        \"\"\" generates the networkx graph representing orso's world with all its paths.\n",
    "\n",
    "        Returns: \n",
    "            graph, positions\n",
    "        \"\"\"\n",
    "        nx_graph = nx.Graph()\n",
    "        for node_id in self.map.keys():\n",
    "            zoom = 0.6\n",
    "            image = self.image_empty_pot\n",
    "            nx_graph.add_node(node_id, image=image, zoom=zoom)\n",
    "        for source, connections in self.map.items():\n",
    "            for target, cost in connections:\n",
    "                if cost >= 300:\n",
    "                    color = 'dodgerblue'\n",
    "                elif cost >= 200:\n",
    "                    color = 'darkgoldenrod'\n",
    "                elif cost >= 100:\n",
    "                    color = 'forestgreen'\n",
    "                else:\n",
    "                    color = 'greenyellow'\n",
    "                nx_graph.add_edge(source, target, color=color, weight=6, image=self.image_cave)\n",
    "        nx_pos = nx.kamada_kawai_layout(nx_graph)\n",
    "        return nx_graph, nx_pos\n",
    "\n",
    "    def _render_to_figure(self):\n",
    "        \"\"\" Renders the current state as a graph with matplotlib\n",
    "        \"\"\"\n",
    "        # draw graph using matplotlib\n",
    "        if self._figure is not None :\n",
    "            plt.close(self._figure)\n",
    "        self._figure = plt.figure(\"BeraterEnv\", figsize=(12, 9))\n",
    "        if len(self._figure.axes) == 0:\n",
    "            self._figure.add_subplot(1, 1, 1)\n",
    "        self._figure.axes[0].cla()\n",
    "        ax = self._figure.axes[0]\n",
    "\n",
    "        edges = self.nx_graph.edges()\n",
    "        edge_colors = [self.nx_graph[u][v]['color'] for u, v in edges]\n",
    "        edge_weights = [self.nx_graph[u][v]['weight'] for u, v in edges]\n",
    "        nx.draw(self.nx_graph, pos=self.nx_pos, ax=ax, node_color='lightgrey',\n",
    "                edges=edges, edge_color=edge_colors, width=edge_weights)\n",
    "\n",
    "        # draw images on graph nodes\n",
    "        # set image (according to the current state) and sizes (make orso's current position larger)\n",
    "        for node_id in self.nx_graph.nodes():\n",
    "            node = self.nx_graph.node[node_id]\n",
    "            node['zoom'] = 0.4\n",
    "            if node_id == self.state:\n",
    "                node['zoom'] = 0.6\n",
    "            if node_id in self._honeypot_places:\n",
    "                node['image'] = self.image_empty_pot\n",
    "                if self.customer_reward[node_id] > 0:\n",
    "                    node['image'] = self.image_honey\n",
    "            else:\n",
    "                node['image'] = None\n",
    "            if node_id == 'S':\n",
    "                node['image'] = self.image_cave\n",
    "            if self.state == node_id:\n",
    "                node['image'] = self.image_orso\n",
    "\n",
    "        # position images\n",
    "        for n in self.nx_pos:\n",
    "            node = self.nx_graph.node[n]\n",
    "            image = node['image']\n",
    "            if image is not None: \n",
    "                xp, yp = self.nx_pos[n]\n",
    "                offset_image = OffsetImage(image, node['zoom'])\n",
    "                offset_image.image.axes = ax\n",
    "                ab = AnnotationBbox(offset_image, (xp, yp),\n",
    "                                    xybox=(0, 0),\n",
    "                                    xycoords='data',\n",
    "                                    boxcoords=\"offset points\",\n",
    "                                    pad=0.0,\n",
    "                                    frameon=False\n",
    "                                    )\n",
    "                ax.add_artist(ab)\n",
    "\n",
    "        self._figure.canvas.draw()\n",
    "\n",
    "    def _render_ansi(self):\n",
    "        result = (\"Episode: \" + (\"%4.0f  \" % self.envEpisodeCount) +\n",
    "                  \" Step: \" + (\"%4.0f  \" % self.stepCount) +\n",
    "                  self.lastStep_state + ' --' + str(self.action) + '-> ' + self.state +\n",
    "                  ' R=' + (\"% 2.2f\" % self.reward) + ' totalR=' + (\"% 3.2f\" % self.totalReward) +\n",
    "                  ' cost=' + (\"%4.0f\" % self.cost) + ' customerR=' + (\"%4.0f\" % self.customerReward) + ' optimum=' + (\n",
    "                          \"%4.0f\" % self.optimum)\n",
    "                  )\n",
    "        return result\n",
    "\n",
    "    def _render_rgb(self):\n",
    "        self._render_to_figure()\n",
    "        self._figure.canvas.draw()\n",
    "        buf = self._figure.canvas.tostring_rgb()\n",
    "        num_cols, num_rows = self._figure.canvas.get_width_height()\n",
    "        plt.close(self._figure)\n",
    "        self._figure = None\n",
    "        result = np.fromstring(buf, dtype=np.uint8).reshape(num_rows, num_cols, 3)\n",
    "        return result\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        if mode == 'ansi':\n",
    "            return self._render_ansi()\n",
    "        elif mode == 'human':\n",
    "            clear_output(wait=True)\n",
    "            self._render_to_figure()\n",
    "            plt.pause(0.01)\n",
    "            return\n",
    "        elif mode == 'rgb_array':\n",
    "            return self._render_rgb()\n",
    "        else:\n",
    "            super().render(mode=mode)\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vKUZ3Pk8I5Rt",
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# First Steps\n",
    "A way to view the visualization: \n",
    "\n",
    "Orso - the bear - lives in his cave (position 'S'). Orso knows his area and where he can \n",
    "typically find some honey (positions 'A' to 'O'). The honey places are scattered all over his home turf and connected\n",
    "by some pathways. Some connections are easy like walking over a grassy field (light green, very low cost) or forests \n",
    "(dark green, low cost), a bit strenuous like walking over a hill (brown, higher costs) and very arduous like swimming \n",
    "through a lake (blue, very high costs).\n",
    "\n",
    "There are other bears around competing for the honey pots. So some spots have honey (yellow nodes) and some\n",
    "are already taken (brown nodes).\n",
    "\n",
    "Every morning, Orso awakes and starts looking for some honey. But every day, the honey pots are at a new place\n",
    "( env.reset() ). So Orso climbs a tree near his cave to find out where the honey is. Even with this knowledge it is not clear which route he should take. Being a bear also means being lazy, so Orso wants to get as much honey as possible while at the lowest costs possible. At each spot he has to decide where to go next (the action). His daily journey ends when his back in his own cave.\n",
    "\n",
    "Be god and create Orso's world:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_fHrBrxxI5Rt",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "b = BeraterEnv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JD9SGkYxI5Rw",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new morning starts (rerun the cell below to see how the honey pots change places). But Orso \n",
    "(depicted in 'fuchsia', Marsha's favorite color ?) doesn't know \n",
    "about the sweetness of honey or his surroundings. So the climbs a tree to get an overview and this is what he sees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "b.reset()\n",
    "b.render() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3u9Rd6YcI5Ry",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Take Orso by his paws and go for a few steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "s2RYX2_2I5Ry",
    "outputId": "8d618bb0-6187-4e5f-8a61-1b1032074b52",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "b.step(1)\n",
    "b.render()\n",
    "print(b.render(mode='ansi'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UjkFXVspI5R1"
   },
   "source": [
    "Note that the honey pot nodes turn brown once Orso has passed and taken the honey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "TtXMSrM0I5R2",
    "outputId": "17bcc585-bd42-435b-95ce-3b18bb59747d",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "b.step(3)\n",
    "b.render()\n",
    "print(b.render(mode='ansi'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EYaTAvAyYO-U"
   },
   "source": [
    "Now Orso must start to learn by himself to take actions to gather all the honey while minimizing the effort:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_uEfpOeeI5R8"
   },
   "source": [
    "# Train policy with tfagents PpoAgent\n",
    "\n",
    "### Register with OpenAI Gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OS3pnnbAI5R9",
    "outputId": "647f20ea-4d4f-4346-e1ec-c304f1382d32",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from easyagents.easyenv import register_with_gym\n",
    "\n",
    "register_with_gym(\"Berater-v1\", BeraterEnv, max_episode_steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zzGp2sTZI5R_"
   },
   "source": [
    "##  Dry run (short training, no logging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q9TVf1pPI5R_",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from easyagents.tfagents import PpoAgent\n",
    "from easyagents.config import TrainingFast\n",
    "from easyagents.config import Logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "r-MT_PYVI5SB",
    "outputId": "4e1ee416-bcd7-497d-d1a7-2a151dd29658",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ppoAgent = PpoAgent(    gym_env_name = 'Berater-v1',                        \n",
    "                        training=TrainingFast(max_steps_per_episode = 50))\n",
    "ppoAgent.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s5XjtqevI5SM"
   },
   "source": [
    "## Some training & logging (default, on custom network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8wWKZBqCI5SN",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from easyagents.tfagents import PpoAgent\n",
    "from easyagents.config import Training\n",
    "\n",
    "ppoAgent = PpoAgent( gym_env_name = 'Berater-v1', fc_layers=(500,500,500), \n",
    "                     training=Training(max_steps_per_episode = 50) )\n",
    "ppoAgent.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vU8UQG6vI5SR"
   },
   "source": [
    "### Visualize trained policy (console and movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "FS6E4aW4I5SV",
    "outputId": "17492083-202f-49c8-e773-582894dacc90",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ppoAgent.render_episodes(num_episodes=1,mode='ansi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 803
    },
    "colab_type": "code",
    "id": "4FbD6aMmI5SW",
    "outputId": "3662f509-1e2e-4e25-88ce-d3afb6004f62",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "ppoAgent.render_episodes_to_jupyter(num_episodes=1, fps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FfO2VaVhI5SY"
   },
   "source": [
    "## Custom training (duration, learning rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gFISrkwhI5SZ",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from easyagents.tfagents import PpoAgent\n",
    "from easyagents.config import Training\n",
    "\n",
    "training=Training( num_iterations = 2500,\n",
    "                   num_episodes_per_iteration = 10,\n",
    "                   max_steps_per_episode = 50,\n",
    "                   num_epochs_per_iteration = 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "x8ZFVRWdI5Sd",
    "outputId": "b5932d8c-40c6-4298-9d42-e423726ac743",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ppoAgent = PpoAgent(    gym_env_name = 'Berater-v1',\n",
    "                        fc_layers=(500,500,500), \n",
    "                        training=training,\n",
    "                        learning_rate=1e-4\n",
    "                   )\n",
    "ppoAgent.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8OJYNSBaI5Sf"
   },
   "source": [
    "### Visualize training and policy (with custom y-limits and movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "JVAsAknHI5Sf",
    "outputId": "5a80b4b4-761f-4086-d3da-9dfb7b99947d",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "_ = ppoAgent.plot_episodes(ylim=[None,(0,1),(0,50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 803
    },
    "colab_type": "code",
    "id": "C0XVkNWaI5Sj",
    "outputId": "642eb860-c5e8-47a7-e6de-7cb18063cf84",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ppoAgent.render_episodes_to_jupyter(num_episodes=1, fps=1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "zpzHtN3-kQ26",
    "w3OdHyWEEEwy",
    "bzoq0VM85p46"
   ],
   "name": "easyagents_berater.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
